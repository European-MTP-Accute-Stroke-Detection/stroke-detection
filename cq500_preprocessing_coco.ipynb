{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CQ500 Preprocessing to COCO format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook if you want to preprocess the CQ500 dataset with bounding boxes to coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('qureai-cq500-boxes-updated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = {\n",
    "  \"info\": {\n",
    "    \"description\": \"Stroke detection dataset\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2023,\n",
    "    \"contributor\": \"Marc Becker\",\n",
    "    \"date_created\": \"2017/09/01\"\n",
    "  },\n",
    "  \"licenses\": [],\n",
    "  \"images\": [],\n",
    "  \"annotations\": [],\n",
    "  \"categories\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"name\": \"Hemmoraghe\",\n",
    "      \"supercategory\": \"Hemmoraghe\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Define the split ratio (e.g., 0.8 for 80% train, 20% validation)\n",
    "split_ratio = 0.8\n",
    "# Create a list of all image filenames\n",
    "import random\n",
    "\n",
    "image_filenames = os.listdir('./data/cq500')\n",
    "random.shuffle(image_filenames)  # Randomly shuffle the images\n",
    "\n",
    "# Split the images into train and validation sets based on the split_ratio\n",
    "train_size = int(len(image_filenames) * split_ratio)\n",
    "train_images = image_filenames[:train_size]\n",
    "val_images = image_filenames[train_size:]\n",
    "\n",
    "# Add metadata for training images\n",
    "coco['images'] = []\n",
    "for filename in train_images:\n",
    "    coco['images'].append({\n",
    "        \"id\": filename.split('.dcm')[0],\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"file_name\": filename\n",
    "    })\n",
    "\n",
    "print(f\"Added metadata for {len(coco['images'])} training images\")\n",
    "\n",
    "# Add metadata for validation images\n",
    "coco['images_val'] = []\n",
    "for filename in val_images:\n",
    "    coco['images_val'].append({\n",
    "        \"id\": filename.split('.dcm')[0],\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"file_name\": filename\n",
    "    })\n",
    "\n",
    "print(f\"Added metadata for {len(coco['images_val'])} validation images\")\n",
    "\n",
    "# Add annotations for training images\n",
    "coco['annotations'] = []\n",
    "for index, row in df.iterrows():\n",
    "    if isinstance(row['data'], str):\n",
    "        bbox = eval(row['data'])\n",
    "        if row['SOPInstanceUID'] + '.dcm' in train_images:\n",
    "            coco['annotations'].append({\n",
    "                \"id\": index,\n",
    "                \"image_id\": row['SOPInstanceUID'],\n",
    "                \"category_id\": 1,\n",
    "                \"bbox\": [bbox['x'], bbox['y'], bbox['width'], bbox['height']],\n",
    "            })\n",
    "\n",
    "print(f\"Added {len(coco['annotations'])} annotations for training set\")\n",
    "\n",
    "# Add annotations for validation images\n",
    "coco['annotations_val'] = []\n",
    "for index, row in df.iterrows():\n",
    "    if isinstance(row['data'], str):\n",
    "        bbox = eval(row['data'])\n",
    "        if row['SOPInstanceUID'] + '.dcm' in val_images:\n",
    "            coco['annotations_val'].append({\n",
    "                \"id\": index,\n",
    "                \"image_id\": row['SOPInstanceUID'],\n",
    "                \"category_id\": 1,\n",
    "                \"bbox\": [bbox['x'], bbox['y'], bbox['width'], bbox['height']],\n",
    "            })\n",
    "            \n",
    "print(f\"Added {len(coco['annotations_val'])} annotations for validation set\")\n",
    "import json\n",
    "\n",
    "# Filter annotations for training and validation sets\n",
    "coco_train = {\n",
    "    \"info\": coco[\"info\"],\n",
    "    \"licenses\": coco[\"licenses\"],\n",
    "    \"images\": coco[\"images\"],\n",
    "    \"annotations\": [anno for anno in coco[\"annotations\"] if anno[\"image_id\"] in train_images],\n",
    "    \"categories\": coco[\"categories\"]\n",
    "}\n",
    "\n",
    "coco_val = {\n",
    "    \"info\": coco[\"info\"],\n",
    "    \"licenses\": coco[\"licenses\"],\n",
    "    \"images\": coco[\"images_val\"],\n",
    "    \"annotations\": [anno for anno in coco[\"annotations_val\"] if anno[\"image_id\"] in val_images],\n",
    "    \"categories\": coco[\"categories\"]\n",
    "}\n",
    "\n",
    "# Save the training and validation data to separate JSON files\n",
    "with open(\"annotations_train.json\", \"w\") as f:\n",
    "    json.dump(coco_train, f, indent=2)\n",
    "\n",
    "with open(\"annotations_val.json\", \"w\") as f:\n",
    "    json.dump(coco_val, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
