{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pydicom\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOPInstanceUID</th>\n",
       "      <th>SeriesInstanceUID</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>data</th>\n",
       "      <th>labelName</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.296485376.1.1521713091...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.3.296485376.1.1521713090...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.2.296485376.1.1521713088...</td>\n",
       "      <td>{'x': 320.95899, 'y': 235.81072999999998, 'wid...</td>\n",
       "      <td>Intraventricular</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.296485376.1.1521713091...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.3.296485376.1.1521713090...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.2.296485376.1.1521713088...</td>\n",
       "      <td>{'x': 320.95899, 'y': 235.81072999999998, 'wid...</td>\n",
       "      <td>Intraventricular</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.296485376.1.1521713091...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.3.296485376.1.1521713090...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.2.296485376.1.1521713088...</td>\n",
       "      <td>{'x': 320.95899, 'y': 235.81072999999998, 'wid...</td>\n",
       "      <td>Intraventricular</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.296485376.1.1521713091...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.3.296485376.1.1521713090...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.2.296485376.1.1521713088...</td>\n",
       "      <td>{'x': 320.95899, 'y': 235.81072999999998, 'wid...</td>\n",
       "      <td>Intraventricular</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.296485376.1.1521713091...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.3.296485376.1.1521713090...</td>\n",
       "      <td>1.2.276.0.7230010.3.1.2.296485376.1.1521713088...</td>\n",
       "      <td>{'x': 318.53628, 'y': 244.69401000000002, 'wid...</td>\n",
       "      <td>Intraventricular</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SOPInstanceUID  \\\n",
       "0  1.2.276.0.7230010.3.1.4.296485376.1.1521713091...   \n",
       "1  1.2.276.0.7230010.3.1.4.296485376.1.1521713091...   \n",
       "2  1.2.276.0.7230010.3.1.4.296485376.1.1521713091...   \n",
       "3  1.2.276.0.7230010.3.1.4.296485376.1.1521713091...   \n",
       "4  1.2.276.0.7230010.3.1.4.296485376.1.1521713091...   \n",
       "\n",
       "                                   SeriesInstanceUID  \\\n",
       "0  1.2.276.0.7230010.3.1.3.296485376.1.1521713090...   \n",
       "1  1.2.276.0.7230010.3.1.3.296485376.1.1521713090...   \n",
       "2  1.2.276.0.7230010.3.1.3.296485376.1.1521713090...   \n",
       "3  1.2.276.0.7230010.3.1.3.296485376.1.1521713090...   \n",
       "4  1.2.276.0.7230010.3.1.3.296485376.1.1521713090...   \n",
       "\n",
       "                                    StudyInstanceUID  \\\n",
       "0  1.2.276.0.7230010.3.1.2.296485376.1.1521713088...   \n",
       "1  1.2.276.0.7230010.3.1.2.296485376.1.1521713088...   \n",
       "2  1.2.276.0.7230010.3.1.2.296485376.1.1521713088...   \n",
       "3  1.2.276.0.7230010.3.1.2.296485376.1.1521713088...   \n",
       "4  1.2.276.0.7230010.3.1.2.296485376.1.1521713088...   \n",
       "\n",
       "                                                data         labelName  number  \n",
       "0  {'x': 320.95899, 'y': 235.81072999999998, 'wid...  Intraventricular      96  \n",
       "1  {'x': 320.95899, 'y': 235.81072999999998, 'wid...  Intraventricular      96  \n",
       "2  {'x': 320.95899, 'y': 235.81072999999998, 'wid...  Intraventricular      96  \n",
       "3  {'x': 320.95899, 'y': 235.81072999999998, 'wid...  Intraventricular      96  \n",
       "4  {'x': 318.53628, 'y': 244.69401000000002, 'wid...  Intraventricular      96  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('qureai-cq500-boxes-updated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all scan numbers that deal with stroke and where we have bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "numbers = set()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  numbers.add(row['number'] - 1)\n",
    "\n",
    "print(len(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy all relevant files from external folder to working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust to your path\n",
    "\n",
    "ext_path = 'D:\\MTP\\CQ500'\n",
    "int_path = './data/cq500'\n",
    "\n",
    "def copy_file(source_file, destination_directory, destination_filename):\n",
    "    try:\n",
    "        shutil.copy(source_file, f\"{destination_directory}/{destination_filename}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Source file not found.\")\n",
    "    except PermissionError:\n",
    "        print(\"Permission error. Make sure you have the necessary permissions.\")\n",
    "    except shutil.Error as e:\n",
    "        print(f\"An error occurred while moving the file: {e}\")\n",
    "\n",
    "def extract_dicom_tags(dicom_file_path):\n",
    "    # Load and read the DICOM file\n",
    "    dicom_dataset = pydicom.dcmread(dicom_file_path)\n",
    "\n",
    "    # Access DICOM tags as dictionary keys\n",
    "    dicom_tags = {}\n",
    "    for tag in dicom_dataset:\n",
    "        tag_name = tag.name\n",
    "        tag_value = tag.value\n",
    "        dicom_tags[tag_name] = tag_value\n",
    "\n",
    "    return dicom_tags\n",
    "\n",
    "def process_file(file_path):\n",
    "    # Do something with the file\n",
    "    tags = extract_dicom_tags(file_path)\n",
    "    if tags['SOP Instance UID'] in df['SOPInstanceUID'].unique():\n",
    "        copy_file(file_path, './data/cq500', tags['SOP Instance UID'] + '.dcm')\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    # Get a list of all files and directories inside the given directory\n",
    "    for entry in os.listdir(directory_path):\n",
    "        full_path = os.path.join(directory_path, entry)\n",
    "\n",
    "        if os.path.isfile(full_path):\n",
    "            # Process the file if it's a regular file\n",
    "            process_file(full_path)\n",
    "\n",
    "        elif os.path.isdir(full_path):\n",
    "            # Recursively process the subdirectory if it's a directory\n",
    "            process_directory(full_path)\n",
    "\n",
    "for num in numbers:\n",
    "  process_directory(f'D:\\MTP\\CQ500\\CQ500CT{num} CQ500CT{num}')\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tensorflow Object Detection CSV Files & Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Shuffle Files into respective directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 18718\n",
      "Test set size: 4680\n"
     ]
    }
   ],
   "source": [
    "# Define the split ratio (e.g., 0.8 for 80% train, 20% validation)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Create a list of all image filenames\n",
    "image_filenames = os.listdir('./data/cq500')\n",
    "random.shuffle(image_filenames)  # Randomly shuffle the images\n",
    "\n",
    "# Split the images into train and validation sets based on the split_ratio\n",
    "train_size = int(len(image_filenames) * split_ratio)\n",
    "train_images = image_filenames[:train_size]\n",
    "test_images = image_filenames[train_size:]\n",
    "\n",
    "# Copy files to respective directories\n",
    "for image_filename in train_images:\n",
    "    copy_file(f\"./data/cq500/{image_filename}\", \"./scans/train\", image_filename)\n",
    "    \n",
    "print(\"Train set size:\", len(train_images))\n",
    "\n",
    "for image_filename in test_images:\n",
    "    copy_file(f\"./data/cq500/{image_filename}\", \"./scans/test\", image_filename)\n",
    "    \n",
    "print(\"Test set size:\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels size: 31674 (79.88%)\n",
      "Test labels size: 7980 (20.12%)\n"
     ]
    }
   ],
   "source": [
    "# Suppress the FutureWarning related to .append() in pandas\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if isinstance(row['data'], str):\n",
    "        bbox = eval(row['data'])\n",
    "        if row['SOPInstanceUID'] + '.dcm' in train_images:\n",
    "            train_list.append({\n",
    "                'filename': row['SOPInstanceUID'] + '.dcm',\n",
    "                'width': 512,\n",
    "                'height': 512,\n",
    "                'xmin': bbox['x'],\n",
    "                'ymin': bbox['y'],\n",
    "                'xmax': bbox['x'] + bbox['width'],\n",
    "                'ymax': bbox['y'] + bbox['height'],\n",
    "                'class': 'hemorrhage'    \n",
    "            })\n",
    "        if row['SOPInstanceUID'] + '.dcm' in test_images:\n",
    "            test_list.append({\n",
    "                'filename': row['SOPInstanceUID'] + '.dcm',\n",
    "                'width': 512,\n",
    "                'height': 512,\n",
    "                'xmin': bbox['x'],\n",
    "                'ymin': bbox['y'],\n",
    "                'xmax': bbox['x'] + bbox['width'],\n",
    "                'ymax': bbox['y'] + bbox['height'],\n",
    "                'class': 'hemorrhage'    \n",
    "            })\n",
    "\n",
    "df_train = pd.DataFrame(train_list)\n",
    "df_test = pd.DataFrame(test_list)\n",
    "            \n",
    "df_train.to_csv('scans/train_labels.csv', index = False, encoding='utf-8')\n",
    "df_test.to_csv('scans/test_labels.csv', index = False, encoding='utf-8')\n",
    "\n",
    "print(f\"Train labels size: {len(df_train)} ({len(df_train) / (len(df_train) + len(df_test))  * 100:.2f}%)\")\n",
    "print(f\"Test labels size: {len(df_test)} ({len(df_test) / (len(df_train) + len(df_test)) * 100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
